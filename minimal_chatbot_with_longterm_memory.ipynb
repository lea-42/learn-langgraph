{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84819234-d3c3-4e8e-b2ea-6db8e787a90d",
   "metadata": {},
   "source": [
    "## Long running persistent conversations\n",
    "Truncate messages and use summarization and persistence to enable long conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f14e5-4767-4db7-9b0b-29b9e2d7d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561caea-7f36-4b79-9684-c32dfd10735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=openai_api_key)\n",
    "\n",
    "class StateWithSummary(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "def summarize_and_truncate(state: StateWithSummary):\n",
    "    prev_summary = state.get(\"summary\")\n",
    "\n",
    "    instruction = (\n",
    "        \"You are an assistant that generates and updates memory summaries from conversations between a user and an AI assistant.\\n\\n\"\n",
    "        \"Your job is to produce a concise but informative summary of the user's preferences, goals, questions, and relevant details.\"\n",
    "    )\n",
    "\n",
    "    if prev_summary:\n",
    "        instruction += (\n",
    "            \"\\n\\nHere is the existing summary you must update:\\n\"\n",
    "            f\"{prev_summary.strip()}\\n\\n\"\n",
    "            \"Update this summary to include any new facts from the following conversation messages.\"\n",
    "        )\n",
    "    else:\n",
    "        instruction += \"\\n\\nCreate a summary based on the following conversation messages.\"\n",
    "\n",
    "    instruction += (\n",
    "        \"\\n\\nRules:\\n\"\n",
    "        \"- Be concise but informative.\\n\"\n",
    "        \"- Focus on key facts, user intent, or assistant advice.\\n\"\n",
    "        \"- Do NOT respond to the messages.\\n\"\n",
    "        \"- The summary will be reused in future prompts.\\n\"\n",
    "    )\n",
    "    response = llm.invoke([SystemMessage(instruction)] + state[\"messages\"][:-2])\n",
    "    summary = response.content\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"messages\": delete_messages\n",
    "    }\n",
    "\n",
    "def respond_to_user(state: StateWithSummary):\n",
    "    summary = state.get(\"summary\")\n",
    "    messages = state[\"messages\"]\n",
    "    if summary:\n",
    "        system_message = f\"\"\"You are an AI assistant. You are continuing a conversation with a user. \n",
    "    \n",
    "        Here is a summary of the previous conversation:\n",
    "        \n",
    "        {summary}\n",
    "    \n",
    "        \n",
    "        Use this information when responding to the user's last message IF AND ONLY IF it is relevant. \n",
    "        Do not change the topic or mix topics unless directed to by the user. \n",
    "        Stay on topic and be precise!\n",
    "        \"\"\"\n",
    "        messages = [SystemMessage(content=system_message)] + messages\n",
    "        \n",
    "    assistant_response = llm.invoke(messages)\n",
    "    return {\"messages\": [assistant_response]}\n",
    "    \n",
    "\n",
    "def should_summarize(state: StateWithSummary) -> Literal[\"summarize_and_truncate\", END]:\n",
    "    # I want to keep at least 2 messages after summary and truncation, so trigger this once the list gets to 4 messages \n",
    "    if len(state.get(\"messages\", [])) > 3: \n",
    "        return \"summarize_and_truncate\"\n",
    "    return END\n",
    "    \n",
    "\n",
    "graph_builder = StateGraph(StateWithSummary)\n",
    "graph_builder.add_node(\"summarize_and_truncate\", summarize_and_truncate)\n",
    "graph_builder.add_node(\"respond_to_user\", respond_to_user)\n",
    "\n",
    "graph_builder.add_edge(START, \"respond_to_user\")\n",
    "graph_builder.add_conditional_edges(\"respond_to_user\", should_summarize)\n",
    "graph_builder.add_edge(\"summarize_and_truncate\", END)\n",
    "\n",
    "db_path = \"state_db/chatbot_min_longterm_convos.db\"\n",
    "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "memory = SqliteSaver(conn)\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(\"```mermaid\\n\" + graph.get_graph().draw_mermaid() + \"\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0eee84-7fed-4a2c-a9cd-4fc2287e94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"thread_id\": \"1\"}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream(\n",
    "        {\"messages\": [HumanMessage(user_input)]},\n",
    "        config\n",
    "    ):\n",
    "        for value in event.values():\n",
    "            if  value[\"messages\"][-1].content:\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\", \"bye\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except Exception as ex:\n",
    "        print(\"Something when wrong, I need to say goodbye!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-ENG-ENV",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
