{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db646c11-8d47-4550-a7c8-2322f1d989d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from typing import Literal\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893a07a-d3eb-43f8-83a3-e23a60ff7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def pet_info(has_pet: bool | None, animal: str | None, pet_name: str | None, message: str | None) -> dict:\n",
    "    \"\"\"Capture whether the user has a pet, what kind of animal, and its name.\"\"\"\n",
    "    return {\n",
    "        \"has_pet\": has_pet,\n",
    "        \"animal\": animal,\n",
    "        \"pet_name\": pet_name,\n",
    "        \"message\": message or \"\"\n",
    "    }\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=openai_api_key)\n",
    "llm_with_tool = llm.bind_tools([pet_info])\n",
    "\n",
    "class State(TypedDict):\n",
    "    has_pet: bool | None\n",
    "    animal: str | None\n",
    "    pet_name: str | None\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    \n",
    "\n",
    "def node_ask_about_pet(state: State):\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a friendly assistant trying to find out if the user has a pet.\n",
    "    Ask friendly, natural questions to figure out if they have a pet, what kind of animal it is, and the pet's name.\n",
    "    \n",
    "    At each step, call the pet_info tool with the information you currently have â€” even if it's incomplete.\n",
    "    The tool has 4 fields: \n",
    "    - has_pet: true/false/null. True - has pet, False - has no pet, null uncertain if the user has a pet or not.\n",
    "    - animal: e.g. dog, cat, etc. or null if unknown\n",
    "    - pet_name: the name or null if unknown \n",
    "    - message: Use this field to add a reply message for the user with questions for missing data.\n",
    "    \n",
    "    \n",
    "    - Call the tool on EVERY turn. Absolutely always call the tool on every turn, no exceptions, even if the user \n",
    "    is off-topic.\n",
    "    - Ask questions to clarify missing information. \n",
    "    - If the user answers with irrelvant information call the tool and send a message that guides them back to the \n",
    "    conversation about the pet.\n",
    "    - If the user says he has no pets set has_pet to False, and leave everything else as null. \n",
    "    - Once you know what kind of animal the pet is and it's name, set those values, but leave the message null.\n",
    "    - If there is missing information ask a friendly question to find out the missing information.\n",
    "    \n",
    "    \"\"\"\n",
    "    }\n",
    "    \n",
    "    messages = [system_prompt] + state.get(\"messages\", [])\n",
    "    response = llm_with_tool.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        tool_calls = response.additional_kwargs.get(\"tool_calls\", [])\n",
    "        if tool_calls:\n",
    "            args = tool_calls[0].get(\"function\", {}).get(\"arguments\")\n",
    "            if isinstance(args, str):\n",
    "                args = json.loads(args)\n",
    "            msg = args.get(\"message\")\n",
    "            return {\n",
    "                \"has_pet\": args.get(\"has_pet\"),\n",
    "                \"animal\": args.get(\"animal\"),\n",
    "                \"pet_name\": args.get(\"pet_name\"),\n",
    "                \"messages\": add_messages(state[\"messages\"], [AIMessage(content=msg)] if msg else [])\n",
    "            }\n",
    "        else:\n",
    "            msg = response.content\n",
    "            return state | {\n",
    "                \"messages\": add_messages(state[\"messages\"], [AIMessage(content=msg)] if msg else [])\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return state | {\"messages\": [AIMessage(content=\"Oops, something went wrong. Can you try rephrasing that?\")]}\n",
    "\n",
    "\n",
    "def node_get_user_input(state: State):\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\", \"bye\", \"\"]:\n",
    "        return state | {\"messages\": [HumanMessage(content=\"Goodbye!\")]}  \n",
    "    return {\n",
    "        \"messages\": add_messages(state[\"messages\"], [HumanMessage(content=user_input)])\n",
    "    }\n",
    "    \n",
    "\n",
    "def node_final_message(state: State): \n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"You are a friendly assistant giving a final response to a user at the end of a chat about his or her pet. \n",
    "        Here's what you know about the user's pet status.\n",
    "        \n",
    "        The user has a pet: {state[\"has_pet\"]}\n",
    "        The type of animal: {state[\"animal\"]}\n",
    "        The name of the pet: {state[\"pet_name\"]}\n",
    "        \n",
    "        Say something nice and then clearly say goodbye so that the user knows for sure that the conversation is over. \n",
    "    \"\"\"\n",
    "    }\n",
    "    messages = [system_prompt]\n",
    "    response = llm.invoke(messages)\n",
    "    return state | {\"messages\": add_messages(state[\"messages\"], [AIMessage(content=response.content)])}\n",
    "    \n",
    "\n",
    "def is_finished(state: State)  -> Literal[\"node_final_message\", \"node_get_user_input\"]:\n",
    "    match state:\n",
    "        case {\"has_pet\": False}:\n",
    "            return \"node_final_message\"\n",
    "        case {\"has_pet\": True, \"animal\": str(), \"pet_name\": str()}:\n",
    "            return \"node_final_message\"\n",
    "        case _:\n",
    "            return \"node_get_user_input\"\n",
    "\n",
    "\n",
    "def build_graph():\n",
    "    graph_builder = StateGraph(State)\n",
    "    graph_builder.add_node(\"node_ask_about_pet\", node_ask_about_pet)\n",
    "    graph_builder.add_node(\"node_get_user_input\", node_get_user_input)\n",
    "    graph_builder.add_node(\"node_final_message\", node_final_message)\n",
    "    \n",
    "    graph_builder.set_entry_point(\"node_ask_about_pet\")\n",
    "    graph_builder.add_edge(\"node_get_user_input\", \"node_ask_about_pet\")\n",
    "    graph_builder.add_conditional_edges(\"node_ask_about_pet\", is_finished)\n",
    "    graph_builder.add_edge(\"node_final_message\", END)\n",
    "    memory = MemorySaver()\n",
    "    graph = graph_builder.compile(checkpointer=memory)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def run_chatbot():\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    state = {\"has_pet\": None, \"animal\": None, \"pet_name\": None, \"messages\": []}\n",
    "    graph = build_graph()\n",
    "    for event in graph.stream(state, config):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and value[\"messages\"]:\n",
    "                last_msg = value[\"messages\"][-1]\n",
    "                if isinstance(last_msg, AIMessage):\n",
    "                    print(\"Bot:\", last_msg.content)\n",
    "            state = value\n",
    "    return {\n",
    "        \"has_pet\": state[\"has_pet\"],\n",
    "        \"animal\": state[\"animal\"],\n",
    "        \"pet_name\": state[\"pet_name\"],\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pet_info = run_chatbot()\n",
    "    print(\"\\n\\nPet Info: \", pet_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-ENG-PERSO-LangGraph",
   "language": "python",
   "name": "ai-eng-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
